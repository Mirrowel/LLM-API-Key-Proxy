services:
  llm-proxy:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-api-proxy
    restart: unless-stopped
    ports:
      - "8317:8317"
    volumes:
      # Mount .env files for configuration
      - ./.env:/app/.env:ro
      # Mount oauth_creds directory for OAuth credentials persistence
      - ./oauth_creds:/app/oauth_creds
      # Mount logs directory for persistent logging
      - ./logs:/app/logs
      # Optionally mount additional .env files (e.g., combined credential files)
      # - ./antigravity_all_combined.env:/app/antigravity_all_combined.env:ro
    environment:
      # Skip OAuth interactive initialization in container (non-interactive)
      - SKIP_OAUTH_INIT_CHECK=true
      # Ensure Python output is not buffered
      - PYTHONUNBUFFERED=1
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8317/')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
